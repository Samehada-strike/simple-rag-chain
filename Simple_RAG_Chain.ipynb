{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cd4b739",
   "metadata": {},
   "source": [
    "### Simple RAG Chain using LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a7f74fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Create data directory\n",
    "DATA_DIR = Path(\"data\")\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "texts = {\n",
    "    \"ml.txt\": \"\"\"Machine Learning (ML) is a subset of artificial intelligence that focuses on\n",
    "building systems that learn from data instead of being explicitly programmed.\n",
    "ML algorithms identify patterns in historical data and use those patterns\n",
    "to make predictions or decisions on new, unseen data.\n",
    "\n",
    "Common examples include spam detection, recommendation systems, and\n",
    "credit risk modeling.\n",
    "\"\"\",\n",
    "\n",
    "    \"dl.txt\": \"\"\"Deep Learning (DL) is a specialized area of Machine Learning that uses\n",
    "neural networks with multiple hidden layers, known as deep neural networks.\n",
    "These models are particularly effective for unstructured data such as images,\n",
    "audio, and text.\n",
    "\n",
    "Popular deep learning architectures include Convolutional Neural Networks (CNNs)\n",
    "and Recurrent Neural Networks (RNNs).\n",
    "\"\"\",\n",
    "\n",
    "    \"nlp.txt\": \"\"\"Natural Language Processing (NLP) is a field of artificial intelligence that\n",
    "enables machines to understand, interpret, and generate human language.\n",
    "NLP combines linguistics, machine learning, and deep learning techniques.\n",
    "\n",
    "Applications of NLP include chatbots, sentiment analysis, and language translation.\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "# Write files\n",
    "for filename, content in texts.items():\n",
    "    (DATA_DIR / filename).write_text(content, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e1100ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    path=\"data\",\n",
    "    glob=\"*.txt\",\n",
    "    loader_cls=TextLoader\n",
    ")\n",
    "\n",
    "raw_documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6ca03136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from typing import List\n",
    "import os\n",
    "\n",
    "def enrich_documents_with_metadata(\n",
    "    documents: List[Document]\n",
    ") -> List[Document]:\n",
    "    enriched_documents = []\n",
    "\n",
    "    for doc in documents:\n",
    "        source_path = doc.metadata.get(\"source\", \"\")\n",
    "        filename = os.path.basename(source_path)\n",
    "\n",
    "        # Infer topic from filename (ml.txt â†’ ML)\n",
    "        topic = os.path.splitext(filename)[0].upper()\n",
    "\n",
    "        enriched_doc = Document(\n",
    "            page_content=doc.page_content,\n",
    "            metadata={\n",
    "                \"topic\": topic,\n",
    "                \"source\": filename\n",
    "            }\n",
    "        )\n",
    "\n",
    "        enriched_documents.append(enriched_doc)\n",
    "\n",
    "    return enriched_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fe5a1b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = enrich_documents_with_metadata(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d80ffcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: {'topic': 'DL', 'source': 'dl.txt'}\n",
      "Content preview: Deep Learning (DL) is a specialized area of Machine Learning that uses\n",
      "neural networks with multiple hidden layers, known as deep neural networks.\n",
      "These models are particularly effective for unstructured data such as images,\n",
      "audio, and text.\n",
      "\n",
      "Popular deep learning architectures include Convolutional Neural Networks (CNNs)\n",
      "and Recurrent Neural Networks (RNNs).\n",
      " \n",
      "\n",
      "Metadata: {'topic': 'ML', 'source': 'ml.txt'}\n",
      "Content preview: Machine Learning (ML) is a subset of artificial intelligence that focuses on\n",
      "building systems that learn from data instead of being explicitly programmed.\n",
      "ML algorithms identify patterns in historical data and use those patterns\n",
      "to make predictions or decisions on new, unseen data.\n",
      "\n",
      "Common examples include spam detection, recommendation systems, and\n",
      "credit risk modeling.\n",
      " \n",
      "\n",
      "Metadata: {'topic': 'NLP', 'source': 'nlp.txt'}\n",
      "Content preview: Natural Language Processing (NLP) is a field of artificial intelligence that\n",
      "enables machines to understand, interpret, and generate human language.\n",
      "NLP combines linguistics, machine learning, and deep learning techniques.\n",
      "\n",
      "Applications of NLP include chatbots, sentiment analysis, and language translation.\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for doc in documents:\n",
    "    print(\"Metadata:\", doc.metadata)\n",
    "    print(\"Content preview:\", doc.page_content, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "529e5bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b528dee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=40,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "69bdc811",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_documents = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "dc388f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1\n",
      "Metadata: {'topic': 'DL', 'source': 'dl.txt'}\n",
      "Content: Deep Learning (DL) is a specialized area of Machine Learning that uses\n",
      "neural networks with multiple hidden layers, known as deep neural networks.\n",
      "------------------------------------------------------------\n",
      "Chunk 2\n",
      "Metadata: {'topic': 'DL', 'source': 'dl.txt'}\n",
      "Content: These models are particularly effective for unstructured data such as images,\n",
      "audio, and text.\n",
      "------------------------------------------------------------\n",
      "Chunk 3\n",
      "Metadata: {'topic': 'DL', 'source': 'dl.txt'}\n",
      "Content: Popular deep learning architectures include Convolutional Neural Networks (CNNs)\n",
      "and Recurrent Neural Networks (RNNs).\n",
      "------------------------------------------------------------\n",
      "Chunk 4\n",
      "Metadata: {'topic': 'ML', 'source': 'ml.txt'}\n",
      "Content: Machine Learning (ML) is a subset of artificial intelligence that focuses on\n",
      "building systems that learn from data instead of being explicitly programmed.\n",
      "------------------------------------------------------------\n",
      "Chunk 5\n",
      "Metadata: {'topic': 'ML', 'source': 'ml.txt'}\n",
      "Content: ML algorithms identify patterns in historical data and use those patterns\n",
      "to make predictions or decisions on new, unseen data.\n",
      "------------------------------------------------------------\n",
      "Chunk 6\n",
      "Metadata: {'topic': 'ML', 'source': 'ml.txt'}\n",
      "Content: Common examples include spam detection, recommendation systems, and\n",
      "credit risk modeling.\n",
      "------------------------------------------------------------\n",
      "Chunk 7\n",
      "Metadata: {'topic': 'NLP', 'source': 'nlp.txt'}\n",
      "Content: Natural Language Processing (NLP) is a field of artificial intelligence that\n",
      "enables machines to understand, interpret, and generate human language.\n",
      "------------------------------------------------------------\n",
      "Chunk 8\n",
      "Metadata: {'topic': 'NLP', 'source': 'nlp.txt'}\n",
      "Content: NLP combines linguistics, machine learning, and deep learning techniques.\n",
      "------------------------------------------------------------\n",
      "Chunk 9\n",
      "Metadata: {'topic': 'NLP', 'source': 'nlp.txt'}\n",
      "Content: Applications of NLP include chatbots, sentiment analysis, and language translation.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(chunked_documents):\n",
    "    print(f\"Chunk {i+1}\")\n",
    "    print(\"Metadata:\", doc.metadata)\n",
    "    print(\"Content:\", doc.page_content)\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ca047d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "EMBEDDING_MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "\n",
    "embedding_model = SentenceTransformer(EMBEDDING_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "54868c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(384,)\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Machine learning is a subset of artificial intelligence.\",\n",
    "    \"Deep learning uses neural networks with many layers.\"\n",
    "]\n",
    "\n",
    "embeddings = embedding_model.encode(texts)\n",
    "\n",
    "print(len(embeddings))        # number of vectors\n",
    "print(embeddings[0].shape)   # embedding dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "498a5502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vec1: np.ndarray, vec2: np.ndarray) -> float:\n",
    "    return np.dot(vec1, vec2) / (\n",
    "        np.linalg.norm(vec1) * np.linalg.norm(vec2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0c63ed77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_similarity(\n",
    "    text1: str,\n",
    "    text2: str,\n",
    "    model: SentenceTransformer\n",
    ") -> float:\n",
    "    embeddings = model.encode([text1, text2])\n",
    "    return cosine_similarity(embeddings[0], embeddings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "75c366f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: 0.3914\n"
     ]
    }
   ],
   "source": [
    "score = text_similarity(\n",
    "    \"Machine learning models learn from data\",\n",
    "    \"Data science involves analyzing data to extract insights\",\n",
    "    embedding_model\n",
    ")\n",
    "\n",
    "print(f\"Similarity score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8977f0a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'topic': 'DL', 'source': 'dl.txt'}, page_content='Deep Learning (DL) is a specialized area of Machine Learning that uses\\nneural networks with multiple hidden layers, known as deep neural networks.'),\n",
       " Document(metadata={'topic': 'DL', 'source': 'dl.txt'}, page_content='These models are particularly effective for unstructured data such as images,\\naudio, and text.'),\n",
       " Document(metadata={'topic': 'DL', 'source': 'dl.txt'}, page_content='Popular deep learning architectures include Convolutional Neural Networks (CNNs)\\nand Recurrent Neural Networks (RNNs).'),\n",
       " Document(metadata={'topic': 'ML', 'source': 'ml.txt'}, page_content='Machine Learning (ML) is a subset of artificial intelligence that focuses on\\nbuilding systems that learn from data instead of being explicitly programmed.'),\n",
       " Document(metadata={'topic': 'ML', 'source': 'ml.txt'}, page_content='ML algorithms identify patterns in historical data and use those patterns\\nto make predictions or decisions on new, unseen data.'),\n",
       " Document(metadata={'topic': 'ML', 'source': 'ml.txt'}, page_content='Common examples include spam detection, recommendation systems, and\\ncredit risk modeling.'),\n",
       " Document(metadata={'topic': 'NLP', 'source': 'nlp.txt'}, page_content='Natural Language Processing (NLP) is a field of artificial intelligence that\\nenables machines to understand, interpret, and generate human language.'),\n",
       " Document(metadata={'topic': 'NLP', 'source': 'nlp.txt'}, page_content='NLP combines linguistics, machine learning, and deep learning techniques.'),\n",
       " Document(metadata={'topic': 'NLP', 'source': 'nlp.txt'}, page_content='Applications of NLP include chatbots, sentiment analysis, and language translation.')]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_documents  # List[Document]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "df3eae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def embed_documents(documents, model):\n",
    "    texts = [doc.page_content for doc in documents]\n",
    "    embeddings = model.encode(texts)\n",
    "\n",
    "    return [\n",
    "        {\n",
    "            \"embedding\": embeddings[i],\n",
    "            \"metadata\": documents[i].metadata,\n",
    "            \"content\": documents[i].page_content\n",
    "        }\n",
    "        for i in range(len(documents))\n",
    "    ]\n",
    "    \n",
    "embedded_chunks = embed_documents(chunked_documents, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "42620227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0883806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=chunked_documents,\n",
    "    embedding=embedding_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9fb1d55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTORSTORE_PATH = \"faiss_store\"\n",
    "\n",
    "vectorstore.save_local(VECTORSTORE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b789363e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.load_local(\n",
    "    VECTORSTORE_PATH,\n",
    "    embeddings=embedding_model,\n",
    "    allow_dangerous_deserialization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e196da2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def search_similar_texts(\n",
    "    query: str,\n",
    "    vectorstore: FAISS,\n",
    "    top_k: int = 3\n",
    ") -> List[Dict]:\n",
    "    results = vectorstore.similarity_search_with_score(\n",
    "        query=query,\n",
    "        k=top_k\n",
    "    )\n",
    "\n",
    "    return [\n",
    "        {\n",
    "            \"score\": score,\n",
    "            \"content\": doc.page_content,\n",
    "            \"metadata\": doc.metadata\n",
    "        }\n",
    "        for doc, score in results\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8ceac067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.4629\n",
      "Metadata: {'topic': 'DL', 'source': 'dl.txt'}\n",
      "Content: Deep Learning (DL) is a specialized area of Machine Learning that uses\n",
      "neural networks with multiple hidden layers, known as deep neural networks.\n",
      "------------------------------------------------------------\n",
      "Score: 0.7776\n",
      "Metadata: {'topic': 'DL', 'source': 'dl.txt'}\n",
      "Content: Popular deep learning architectures include Convolutional Neural Networks (CNNs)\n",
      "and Recurrent Neural Networks (RNNs).\n",
      "------------------------------------------------------------\n",
      "Score: 0.8777\n",
      "Metadata: {'topic': 'ML', 'source': 'ml.txt'}\n",
      "Content: Machine Learning (ML) is a subset of artificial intelligence that focuses on\n",
      "building systems that learn from data instead of being explicitly programmed.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "results = search_similar_texts(\n",
    "    query=\"What is deep learning?\",\n",
    "    vectorstore=vectorstore,\n",
    "    top_k=3\n",
    ")\n",
    "\n",
    "for r in results:\n",
    "    print(f\"Score: {r['score']:.4f}\")\n",
    "    print(\"Metadata:\", r[\"metadata\"])\n",
    "    print(\"Content:\", r[\"content\"])\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3f66a8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "assert os.getenv(\"HF_TOKEN\") is not None, \"HF_TOKEN not loaded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c8bf6dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "\n",
    "llm = ChatHuggingFace(\n",
    "    llm=HuggingFaceEndpoint(\n",
    "        repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "        task=\"text-generation\",\n",
    "        max_new_tokens=512,\n",
    "        temperature=0.0,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "24872a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=' The founder of Meesho is IIT Delhi alumnus Vishal Mehta along with Sanjeev Barnwal and Akhil Sacchaney. They started Meesho in 2015 with the intention of making e-commerce accessible to everyone in India, especially those in smaller towns and rural areas. The company operates a social commerce platform where users can sell products through social media networks like WhatsApp.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 89, 'prompt_tokens': 16, 'total_tokens': 105}, 'model_name': 'mistralai/Mistral-7B-Instruct-v0.2', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b64af-421a-7e60-a227-7c92060ec3ec-0' usage_metadata={'input_tokens': 16, 'output_tokens': 89, 'total_tokens': 105}\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\n",
    "    \"Answer briefly:\\nFpunder of Meesho??\"\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "29944694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are a helpful assistant.\n",
    "Answer the question using ONLY the provided context.\n",
    "If the answer is not present in the context, say \"I don't know\".\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6be0fb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1 COMPLETE: Retriever created from FAISS vector store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Create a retriever from the FAISS vector store\n",
    "# -----------------------------------------------\n",
    "# This converts the vector store into a search component\n",
    "# that can fetch the top-k most relevant chunks for a query\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",  # cosine similarity\n",
    "    search_kwargs={\"k\": 3}     # fetch top 3 relevant chunks\n",
    ")\n",
    "\n",
    "print(\"STEP 1 COMPLETE: Retriever created from FAISS vector store\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "28c08fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: Define a function to format retrieved documents\n",
    "# -------------------------------------------------------\n",
    "# Input  : List[Document]\n",
    "# Output : Single formatted string to be injected into the prompt\n",
    "\n",
    "def format_docs(docs):\n",
    "    print(\"STEP 2: Formatting retrieved documents into context\\n\")\n",
    "\n",
    "    formatted_chunks = []\n",
    "\n",
    "    for i, doc in enumerate(docs):\n",
    "        chunk_text = f\"\"\"\n",
    "Chunk {i+1} (Source: {doc.metadata.get('source')} | Topic: {doc.metadata.get('topic')}):\n",
    "{doc.page_content}\n",
    "\"\"\"\n",
    "        formatted_chunks.append(chunk_text)\n",
    "\n",
    "    final_context = \"\\n\".join(formatted_chunks)\n",
    "\n",
    "    print(\"Formatted Context Passed to Prompt:\\n\")\n",
    "    print(final_context)\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    return final_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "529c71f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 3: User Question:\n",
      "What is deep learning?\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: Example user question\n",
    "# -----------------------------\n",
    "question = \"What is deep learning?\"\n",
    "\n",
    "print(\"STEP 3: User Question:\")\n",
    "print(question)\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8893738c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 4 COMPLETE: LCEL RAG chain constructed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# STEP 4: Build the RAG chain using LCEL\n",
    "# -------------------------------------\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        # The question flows unchanged\n",
    "        \"question\": RunnablePassthrough(),\n",
    "\n",
    "        # The same question is used to retrieve documents\n",
    "        \"context\": retriever | format_docs\n",
    "    }\n",
    "    # Inject context + question into the prompt template\n",
    "    | prompt\n",
    "\n",
    "    # Send the formatted prompt to the LLM\n",
    "    | llm\n",
    "\n",
    "    # Convert LLM output to plain string\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"STEP 4 COMPLETE: LCEL RAG chain constructed\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0801baa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 5: Running RAG chain...\n",
      "\n",
      "STEP 2: Formatting retrieved documents into context\n",
      "\n",
      "Formatted Context Passed to Prompt:\n",
      "\n",
      "\n",
      "Chunk 1 (Source: dl.txt | Topic: DL):\n",
      "Deep Learning (DL) is a specialized area of Machine Learning that uses\n",
      "neural networks with multiple hidden layers, known as deep neural networks.\n",
      "\n",
      "\n",
      "Chunk 2 (Source: dl.txt | Topic: DL):\n",
      "Popular deep learning architectures include Convolutional Neural Networks (CNNs)\n",
      "and Recurrent Neural Networks (RNNs).\n",
      "\n",
      "\n",
      "Chunk 3 (Source: ml.txt | Topic: ML):\n",
      "Machine Learning (ML) is a subset of artificial intelligence that focuses on\n",
      "building systems that learn from data instead of being explicitly programmed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "FINAL ANSWER:\n",
      "\n",
      " Deep learning is a specialized area of Machine Learning that uses neural networks with multiple hidden layers.\n"
     ]
    }
   ],
   "source": [
    "# STEP 5: Execute the RAG chain\n",
    "# ----------------------------\n",
    "\n",
    "print(\"STEP 5: Running RAG chain...\\n\")\n",
    "\n",
    "response = rag_chain.invoke(question)\n",
    "\n",
    "print(\"FINAL ANSWER:\\n\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Simple_RAG_Chain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
